{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple-machines Federated Learning\n",
    "Choose your role! We need one server, one/two malicious clients, and several honest clients.\n",
    "\n",
    "Requirements:\n",
    "- Run ```pip install -r requirements.txt```\n",
    "- Run ```ifconfig``` to find your IP address, and check under en0 (for Wi-Fi) or en7 (for Ethernet/cable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Union, Optional, Dict\n",
    "from flwr.common import Parameters, Scalar, Metrics\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.common import FitRes\n",
    "import argparse\n",
    "import torch\n",
    "import utils\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "# Config_client\n",
    "def fit_config(server_round: int):\n",
    "    \"\"\"Return training configuration dict for each round.\"\"\"\n",
    "    config = {\n",
    "        \"current_round\": server_round,\n",
    "        \"local_epochs\": 2,\n",
    "        \"tot_rounds\": 20,\n",
    "    }\n",
    "    return config\n",
    "\n",
    "# Custom weighted average function\n",
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    validities = [num_examples * m[\"validity\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples), \"validity\": sum(validities) / sum(examples)}\n",
    "\n",
    "# Custom strategy to save model after each round\n",
    "class SaveModelStrategy(fl.server.strategy.FedAvg):\n",
    "    def __init__(self, model, data_type, checkpoint_folder, dataset, fold, model_config, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.model = model\n",
    "        self.data_type = data_type\n",
    "        self.checkpoint_folder = checkpoint_folder\n",
    "        self.dataset = dataset\n",
    "        self.model_config = model_config\n",
    "        self.fold = fold\n",
    "\n",
    "        # read data for testing\n",
    "        self.X_test, self.y_test = utils.load_data_test(data_type=self.data_type, dataset=self.dataset)\n",
    "\n",
    "        if self.dataset == 'diabetes':\n",
    "            # randomly pick N samples <= 10605\n",
    "            idx = np.random.choice(len(self.X_test), 300, replace=False)\n",
    "            self.X_test = self.X_test[idx]\n",
    "            self.y_test = self.y_test[idx]\n",
    "        elif self.dataset == 'breast':\n",
    "            # randomly pick N samples <= 89\n",
    "            idx = np.random.choice(len(self.X_test), 88, replace=False)\n",
    "            self.X_test = self.X_test[idx]\n",
    "            self.y_test = self.y_test[idx] \n",
    "        elif self.dataset == 'synthetic':\n",
    "            # randomly pick N samples <= 938\n",
    "            idx = np.random.choice(len(self.X_test), 300, replace=False)\n",
    "            self.X_test = self.X_test[idx]\n",
    "            self.y_test = self.y_test[idx]\n",
    "        elif self.dataset == 'mnist':\n",
    "            # randomly pick N samples <= 938\n",
    "            idx = np.random.choice(len(self.X_test), 300, replace=False)\n",
    "            self.X_test = self.X_test[idx]\n",
    "            self.y_test = self.y_test[idx] \n",
    "        elif self.dataset == 'cifar10':\n",
    "            # randomly pick N samples <= 938\n",
    "            idx = np.random.choice(len(self.X_test), 280, replace=False)\n",
    "            self.X_test = self.X_test[idx]\n",
    "            self.y_test = self.y_test[idx]      \n",
    "        \n",
    "        print(f\"Used Size Server-Test Set: {self.X_test.shape}\")\n",
    "\n",
    "        # create folder if not exists\n",
    "        if not os.path.exists(self.checkpoint_folder + f\"{self.data_type}\"):\n",
    "            os.makedirs(self.checkpoint_folder + f\"{self.data_type}\")\n",
    "\n",
    "    # Override aggregate_fit method to add saving functionality\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[fl.server.client_proxy.ClientProxy, fl.common.FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate model weights using weighted average and store checkpoint\"\"\"\n",
    "\n",
    "        # Perform evaluation on the server side on each single client after local training for each clients evaluate the model\n",
    "        client_data = {}\n",
    "        for client, fit_res in results:\n",
    "            # Load model\n",
    "            params = fl.common.parameters_to_ndarrays(fit_res.parameters)\n",
    "            params_dict = zip(self.model.state_dict().keys(), params)\n",
    "            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "            cid = int(np.round(state_dict['cid'].item()))\n",
    "            self.model.load_state_dict(state_dict, strict=True)\n",
    "            # Evaluate the model\n",
    "            try:\n",
    "                client_metrics = utils.server_side_evaluation(self.X_test, self.y_test, model=self.model, config=self.model_config)\n",
    "                client_data[cid] = client_metrics\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred during server-side evaluation of client {cid}: {e}, returning zero metrics\") \n",
    "\n",
    "        # Planes construction\n",
    "        utils.creation_planes_FBPs(client_data, server_round, self.data_type, self.dataset, self.model_config, self.fold)\n",
    "        \n",
    "        # Call aggregate_fit from base class (FedAvg) to aggregate parameters and metrics\n",
    "        aggregated_parameters, aggregated_metrics = super().aggregate_fit(server_round, results, failures) # aggregated_metrics from aggregate_fit is empty except if i pass fit_metrics_aggregation_fn\n",
    "\n",
    "        # Save model\n",
    "        if aggregated_parameters is not None:\n",
    "\n",
    "            print(f\"Saving round {server_round} aggregated_parameters...\")\n",
    "            # Convert `Parameters` to `List[np.ndarray]`\n",
    "            aggregated_ndarrays: List[np.ndarray] = fl.common.parameters_to_ndarrays(aggregated_parameters)\n",
    "            # Convert `List[np.ndarray]` to PyTorch`state_dict`\n",
    "            params_dict = zip(self.model.state_dict().keys(), aggregated_ndarrays)\n",
    "            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "            self.model.load_state_dict(state_dict, strict=True)\n",
    "            # Save the model\n",
    "            torch.save(self.model.state_dict(), self.checkpoint_folder + f\"{self.data_type}/model_round_{server_round}.pth\")\n",
    "        \n",
    "        return aggregated_parameters, aggregated_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup arguments and initialize strategy\n",
    "class Args:\n",
    "    rounds = 50\n",
    "    data_type = '2cluster'\n",
    "    dataset = 'diabetes'\n",
    "    model = 'net'\n",
    "    pers = 0\n",
    "    n_clients = 5\n",
    "    n_attackers = 1\n",
    "    attack_type = 'DP_flip'\n",
    "    fold = 0\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-28 14:49:31,190 | app.py:163 | Starting Flower server, config: ServerConfig(num_rounds=50, round_timeout=None)\n",
      "INFO flwr 2024-08-28 14:49:31,208 | app.py:176 | Flower ECE: gRPC server running (50 rounds), SSL is disabled\n",
      "INFO flwr 2024-08-28 14:49:31,208 | server.py:89 | Initializing global parameters\n",
      "INFO flwr 2024-08-28 14:49:31,209 | server.py:276 | Requesting initial parameters from one random client\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Size Server-Test Set: torch.Size([300, 21])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Start Flower server for three rounds of federated learning\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_server\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0.0.0.0:8098\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# 0.0.0.0 listens to all available interfaces\u001b[39;49;00m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mServerConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrounds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Print training time in minutes (grey color)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m training_time \u001b[38;5;241m=\u001b[39m (time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/CF_FL/lib/python3.12/site-packages/flwr/server/app.py:184\u001b[0m, in \u001b[0;36mstart_server\u001b[0;34m(server_address, server, config, strategy, client_manager, grpc_max_message_length, certificates)\u001b[0m\n\u001b[1;32m    176\u001b[0m log(\n\u001b[1;32m    177\u001b[0m     INFO,\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlower ECE: gRPC server running (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m rounds), SSL is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    179\u001b[0m     initialized_config\u001b[38;5;241m.\u001b[39mnum_rounds,\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menabled\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m certificates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisabled\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    181\u001b[0m )\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitialized_server\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitialized_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# Stop the gRPC server\u001b[39;00m\n\u001b[1;32m    190\u001b[0m grpc_server\u001b[38;5;241m.\u001b[39mstop(grace\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/CF_FL/lib/python3.12/site-packages/flwr/server/app.py:225\u001b[0m, in \u001b[0;36mrun_fl\u001b[0;34m(server, config)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_fl\u001b[39m(\n\u001b[1;32m    221\u001b[0m     server: Server,\n\u001b[1;32m    222\u001b[0m     config: ServerConfig,\n\u001b[1;32m    223\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m History:\n\u001b[1;32m    224\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train a model on the given server and return the History object.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m     log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapp_fit: losses_distributed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(hist\u001b[38;5;241m.\u001b[39mlosses_distributed))\n\u001b[1;32m    227\u001b[0m     log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapp_fit: metrics_distributed_fit \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(hist\u001b[38;5;241m.\u001b[39mmetrics_distributed_fit))\n",
      "File \u001b[0;32m~/miniforge3/envs/CF_FL/lib/python3.12/site-packages/flwr/server/server.py:90\u001b[0m, in \u001b[0;36mServer.fit\u001b[0;34m(self, num_rounds, timeout)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Initialize parameters\u001b[39;00m\n\u001b[1;32m     89\u001b[0m log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializing global parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_initial_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating initial parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     92\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;241m0\u001b[39m, parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters)\n",
      "File \u001b[0;32m~/miniforge3/envs/CF_FL/lib/python3.12/site-packages/flwr/server/server.py:277\u001b[0m, in \u001b[0;36mServer._get_initial_parameters\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;66;03m# Get initial parameters from one of the clients\u001b[39;00m\n\u001b[1;32m    276\u001b[0m log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequesting initial parameters from one random client\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 277\u001b[0m random_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    278\u001b[0m ins \u001b[38;5;241m=\u001b[39m GetParametersIns(config\u001b[38;5;241m=\u001b[39m{})\n\u001b[1;32m    279\u001b[0m get_parameters_res \u001b[38;5;241m=\u001b[39m random_client\u001b[38;5;241m.\u001b[39mget_parameters(ins\u001b[38;5;241m=\u001b[39mins, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/miniforge3/envs/CF_FL/lib/python3.12/site-packages/flwr/server/client_manager.py:187\u001b[0m, in \u001b[0;36mSimpleClientManager.sample\u001b[0;34m(self, num_clients, min_num_clients, criterion)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m min_num_clients \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     min_num_clients \u001b[38;5;241m=\u001b[39m num_clients\n\u001b[0;32m--> 187\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_num_clients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Sample clients which meet the criterion\u001b[39;00m\n\u001b[1;32m    189\u001b[0m available_cids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclients)\n",
      "File \u001b[0;32m~/miniforge3/envs/CF_FL/lib/python3.12/site-packages/flwr/server/client_manager.py:132\u001b[0m, in \u001b[0;36mSimpleClientManager.wait_for\u001b[0;34m(self, num_clients, timeout)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait until at least `num_clients` are available.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03mBlocks until the requested number of clients is available or until a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03msuccess : bool\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cv:\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclients\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_clients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/CF_FL/lib/python3.12/threading.py:390\u001b[0m, in \u001b[0;36mCondition.wait_for\u001b[0;34m(self, predicate, timeout)\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m waittime \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    389\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaittime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m     result \u001b[38;5;241m=\u001b[39m predicate()\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniforge3/envs/CF_FL/lib/python3.12/threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 359\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start server\n",
    "if not os.path.exists(f\"results/{args.model}/{args.dataset}/{args.data_type}/{args.fold}\"):\n",
    "    os.makedirs(f\"results/{args.model}/{args.dataset}/{args.data_type}/{args.fold}\")\n",
    "else:\n",
    "    # remove the directory and create a new one\n",
    "    os.system(f\"rm -r results/{args.model}/{args.dataset}/{args.data_type}/{args.fold}\")\n",
    "    os.makedirs(f\"results/{args.model}/{args.dataset}/{args.data_type}/{args.fold}\")\n",
    "\n",
    "# model and history folder\n",
    "model = utils.models[args.model]\n",
    "config = utils.config_tests[args.dataset][args.model]\n",
    "\n",
    "# Define strategy\n",
    "strategy = SaveModelStrategy(\n",
    "    model=model(config=config), # model to be trained\n",
    "    min_fit_clients=args.n_clients+args.n_attackers, # Never sample less than 10 clients for training\n",
    "    min_evaluate_clients=args.n_clients+args.n_attackers,  # Never sample less than 5 clients for evaluation\n",
    "    min_available_clients=args.n_clients+args.n_attackers, # Wait until all 10 clients are available\n",
    "    fraction_fit=1.0, # Sample 100 % of available clients for training\n",
    "    fraction_evaluate=1.0, # Sample 100 % of available clients for evaluation\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,\n",
    "    on_evaluate_config_fn=fit_config,\n",
    "    on_fit_config_fn=fit_config,\n",
    "    data_type=args.data_type,\n",
    "    checkpoint_folder=config['checkpoint_folder'],\n",
    "    dataset=args.dataset,\n",
    "    fold=args.fold,\n",
    "    model_config=config,\n",
    ")\n",
    "\n",
    "# Start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Start Flower server for three rounds of federated learning\n",
    "history = fl.server.start_server(\n",
    "    server_address=\"0.0.0.0:8098\",   # 0.0.0.0 listens to all available interfaces\n",
    "    config=fl.server.ServerConfig(num_rounds=args.rounds),\n",
    "    strategy=strategy,\n",
    ")\n",
    "\n",
    "# Print training time in minutes (grey color)\n",
    "training_time = (time.time() - start_time)/60\n",
    "print(f\"\\033[90mTraining time: {round(training_time, 2)} minutes\\033[0m\")\n",
    "time.sleep(1)\n",
    "\n",
    "# convert history to list\n",
    "loss = [k[1] for k in history.losses_distributed]\n",
    "accuracy = [k[1] for k in history.metrics_distributed['accuracy']]\n",
    "validity = [k[1] for k in history.metrics_distributed['validity']]\n",
    "\n",
    "# Save loss and accuracy to a file\n",
    "print(f\"Saving metrics to as .json in histories folder...\")\n",
    "# # check if folder exists and save metrics\n",
    "if not os.path.exists(config['history_folder'] + f\"server_{args.data_type}\"):\n",
    "    os.makedirs(config['history_folder'] + f\"server_{args.data_type}\")\n",
    "with open(config['history_folder'] + f'server_{args.data_type}/metrics_{args.rounds}_{args.attack_type}_{args.n_attackers}_none_{args.fold}.json', 'w') as f:\n",
    "    json.dump({'loss': loss, 'accuracy': accuracy, 'validity':validity}, f)\n",
    "\n",
    "# Single Plot\n",
    "best_loss_round, best_acc_round = utils.plot_loss_and_accuracy(args, loss, accuracy, validity, config=config, show=False)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "if args.model == 'predictor':\n",
    "    y_test_pred, accuracy = utils.evaluation_central_test_predictor(args, best_model_round=best_loss_round, config=config)\n",
    "    print(f\"Accuracy on test set: {accuracy}\")\n",
    "    df_excel = {}\n",
    "    df_excel['accuracy'] = [accuracy]\n",
    "    df_excel = pd.DataFrame(df_excel)\n",
    "    df_excel.to_excel(f\"results_fold_{args.fold}.xlsx\")\n",
    "else:\n",
    "    utils.evaluation_central_test(args, best_model_round=best_loss_round, model=model, config=config)\n",
    "    \n",
    "    # Evaluate distance with all training sets\n",
    "    df_excel = utils.evaluate_distance(args, best_model_round=best_loss_round, model_fn=model, config=config, spec_client_val=False, training_time=training_time)\n",
    "    if args.fold != 0:\n",
    "        df_excel.to_excel(f\"results_fold_{args.fold}.xlsx\")\n",
    "\n",
    "# personalization (now done on the server but can be uqually done on the client side) \n",
    "if args.pers == 1:\n",
    "    start_time = time.time()\n",
    "    # Personalization\n",
    "    print(\"\\n\\n\\n\\n\\033[94mPersonalization\\033[0m\")\n",
    "    df_excel_list = utils.personalization(args, model_fn=model, config=config, best_model_round=best_loss_round)\n",
    "    if args.fold != 0:\n",
    "        for i in range(args.n_clients):\n",
    "            print(f\"Saving results_fold_{args.fold}_personalization_{i+1}.xlsx\")\n",
    "            df_excel_list[i].to_excel(f\"results_fold_{args.fold}_personalization_{i+1}.xlsx\")\n",
    "\n",
    "    # Print training time in minutes (grey color)\n",
    "    print(f\"\\033[90mPersonalization time: {round((time.time() - start_time)/60, 2)} minutes\\033[0m\")\n",
    "\n",
    "# Create gif\n",
    "utils.create_gif(args, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Malicious Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraies\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import utils\n",
    "import flwr as fl\n",
    "import argparse\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the arguments directly in the notebook\n",
    "class Args:\n",
    "    id = 1  # Example: Set the id to 1 (adjust as needed)\n",
    "    data_type = '2cluster'  # Choose between 'random', 'cluster', '2cluster'\n",
    "    dataset = 'diabetes'  # Choose between 'diabetes', 'breast', 'synthetic', 'mnist', 'cifar10'\n",
    "    model = 'net'  # Choose between 'net', 'vcnet', 'predictor'\n",
    "    attack_type = 'MP_random'  # Choose the attack type or set to 'None'\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions \n",
    "# Define Flower client\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, X_train, y_train, X_val, y_val, optimizer, num_examples, \n",
    "                 client_id, data_type, train_fn, evaluate_fn, attack_type, config_model):\n",
    "        self.model = model\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.loss_fn = utils.InvertedLoss() if attack_type==\"DP_inverted_loss\" else torch.nn.CrossEntropyLoss()\n",
    "        self.optimizer = optimizer\n",
    "        self.num_examples = num_examples\n",
    "        self.client_id = client_id \n",
    "        self.data_type = data_type\n",
    "        self.train_fn = train_fn\n",
    "        self.evaluate_fn = evaluate_fn\n",
    "        self.history_folder = config_model['history_folder']\n",
    "        self.config_model = config_model\n",
    "        self.attack_type = attack_type\n",
    "        self.saved_models = {} # Save the parameters of the previous rounds\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        params = []\n",
    "        for k, v in self.model.state_dict().items():\n",
    "            if k == 'cid':\n",
    "                params.append(np.array([self.client_id + 100]))\n",
    "                continue\n",
    "            if k == 'mask' or k=='binary_feature':\n",
    "                params.append(v.cpu().numpy())\n",
    "                continue\n",
    "            # Original parameters\n",
    "            if self.attack_type in [\"None\", \"DP_flip\", \"DP_random\", \"DP_inverted_loss\", \"DP_inverted_loss_cf\"]:\n",
    "                params.append(v.cpu().numpy())\n",
    "            # Mimic the actual parameter range by observing the mean and std of each parameter\n",
    "            elif self.attack_type == \"MP_random\":\n",
    "                v = v.cpu().numpy()\n",
    "                params.append(np.random.normal(loc=np.mean(v), scale=np.std(v), size=v.shape).astype(np.float32))\n",
    "            # Introducing random noise to the parameters\n",
    "            elif self.attack_type == \"MP_noise\":\n",
    "                v = v.cpu().numpy()\n",
    "                params.append(v + np.random.normal(0, 1.2*np.std(v), v.shape).astype(np.float32))   \n",
    "            # Gradient-based attack - flip the sign of the gradient and scale it by a factor [adaptation of Fall of Empires]\n",
    "            elif self.attack_type == \"MP_gradient\": # Fall of Empires\n",
    "                if config[\"current_round\"] == 1:\n",
    "                    params.append(v.cpu().numpy()) # Use the original parameters for the first round\n",
    "                    continue\n",
    "                else:\n",
    "                    epsilon = 0.1 # from 0 to 10 --- reverse gradient when epsilon is equal to learning rate\n",
    "                    learning_rate = 0.01\n",
    "                    prev_v = self.saved_models.get(config[\"current_round\"] - 1).get(k).cpu().numpy()\n",
    "                    current_v = v.cpu().numpy()\n",
    "                    gradient = (prev_v - current_v)/learning_rate # precisely mean gradients from all the other clients\n",
    "                    manipulated_param = current_v + epsilon * gradient  # apply gradient in the opposite direction\n",
    "                    params.append(manipulated_param.astype(np.float32))\n",
    "\n",
    "        return params\n",
    "    \n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "    \n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        if self.attack_type in [\"None\", \"DP_flip\", \"DP_random\", \"DP_inverted_loss\"]:\n",
    "            try:\n",
    "                model_trained, train_loss, val_loss, acc, acc_prime, acc_val, _ = self.train_fn(\n",
    "                    self.model, self.loss_fn, self.optimizer, self.X_train, self.y_train, \n",
    "                    self.X_val, self.y_val, n_epochs=config[\"local_epochs\"], print_info=False, config=self.config_model)\n",
    "            except Exception as e:\n",
    "                # print(f\"An error occurred during training of Malicious client: {e}, returning model with error\") \n",
    "                print(f\"An error occurred during training of Malicious client, returning model with error\") \n",
    "\n",
    "        elif self.attack_type in [\"DP_inverted_loss_cf\"]:\n",
    "            try:\n",
    "                model_trained, train_loss, val_loss, acc, acc_prime, acc_val, _ = self.train_fn(\n",
    "                    self.model, self.loss_fn, self.optimizer, self.X_train, self.y_train, \n",
    "                    self.X_val, self.y_val, n_epochs=config[\"local_epochs\"], print_info=False, config=self.config_model, inv_loss_cf=True)\n",
    "            except Exception as e:\n",
    "                # print(f\"An error occurred during training of Malicious client: {e}, returning model with error\") \n",
    "                print(f\"An error occurred during training of Malicious client, returning model with error\")\n",
    "\n",
    "        elif self.attack_type == \"MP_gradient\":\n",
    "            self.saved_models[config[\"current_round\"]] = {k: v.clone() for k, v in self.model.state_dict().items()}\n",
    "            # delede previous 3-rounds model\n",
    "            if config[\"current_round\"] > 3:\n",
    "                del self.saved_models[config[\"current_round\"]-3]\n",
    "        return self.get_parameters(config), self.num_examples[\"trainset\"], {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        if self.model.__class__.__name__ == \"Predictor\":\n",
    "            try:\n",
    "                loss, accuracy = utils.evaluate_predictor(self.model, self.X_val, self.y_val, self.loss_fn, config=self.config_model)\n",
    "                # save loss and accuracy client\n",
    "                utils.save_client_metrics(config[\"current_round\"], loss, accuracy, 0, client_id=self.client_id,\n",
    "                                        data_type=self.data_type, tot_rounds=config['tot_rounds'], history_folder=self.history_folder)\n",
    "                return float(loss), self.num_examples[\"valset\"], {\"accuracy\": float(accuracy), \"mean_distance\": float(0), \"validity\": float(0)}\n",
    "            except Exception as e:\n",
    "                #print(f\"An error occurred during inference of Malicious client: {e}, returning same zero metrics\") \n",
    "                print(f\"An error occurred during inference of Malicious client, returning same zero metrics\")\n",
    "                return float(10000), self.num_examples[\"valset\"], {\"accuracy\": float(0), \"mean_distance\": float(10000), \"validity\": float(0)}\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                loss, accuracy, validity, mean_proximity, hamming_distance, euclidian_distance, iou, variability = self.evaluate_fn(self.model, self.X_val, self.y_val, self.loss_fn, self.X_train, self.y_train, config=self.config_model)\n",
    "                # save loss and accuracy client\n",
    "                utils.save_client_metrics(config[\"current_round\"], loss, accuracy, validity, mean_proximity, hamming_distance, euclidian_distance, iou, variability,\n",
    "                                        self.client_id, self.data_type, config['tot_rounds'], self.history_folder)\n",
    "                return float(loss), self.num_examples[\"valset\"], {\"accuracy\": float(accuracy), \"proximity\": float(mean_proximity), \"validity\": float(validity),\n",
    "                                                                \"hamming_distance\": float(hamming_distance), \"euclidian_distance\": float(euclidian_distance),\n",
    "                                                                \"iou\": float(iou), \"variability\": float(variability)}\n",
    "            except Exception as e:\n",
    "                # print(f\"An error occurred during inference of Malicious client: {e}, returning same zero metrics\") \n",
    "                print(f\"An error occurred during inference of Malicious client, returning same zero metrics\")\n",
    "                return float(10000), self.num_examples[\"valset\"], {\"accuracy\": float(0), \"proximity\": float(10000), \"validity\": float(0),\n",
    "                                                                \"hamming_distance\": float(10000), \"euclidian_distance\": float(10000),\n",
    "                                                                \"iou\": float(0), \"variability\": float(0)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-28 14:50:07,419 | grpc.py:52 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flwr 2024-08-28 14:50:07,420 | connection.py:42 | ChannelConnectivity.IDLE\n",
      "DEBUG flwr 2024-08-28 14:50:07,421 | connection.py:42 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flwr 2024-08-28 14:50:07,422 | connection.py:42 | ChannelConnectivity.READY\n",
      "DEBUG flwr 2024-08-28 14:50:14,827 | connection.py:141 | gRPC channel closed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Start Flower client\u001b[39;00m\n\u001b[1;32m     26\u001b[0m client \u001b[38;5;241m=\u001b[39m FlowerClient(model, X_train, y_train, X_val, y_val, optimizer, num_examples, args\u001b[38;5;241m.\u001b[39mid, args\u001b[38;5;241m.\u001b[39mdata_type,\n\u001b[1;32m     27\u001b[0m                         train_fn, evaluate_fn, args\u001b[38;5;241m.\u001b[39mattack_type, config)\u001b[38;5;241m.\u001b[39mto_client()\n\u001b[0;32m---> 28\u001b[0m \u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[::]:8098\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# local host\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/CF_FL/lib/python3.12/site-packages/flwr/client/app.py:275\u001b[0m, in \u001b[0;36mstart_client\u001b[0;34m(server_address, load_callable_fn, client_fn, client, grpc_max_message_length, root_certificates, insecure, transport)\u001b[0m\n\u001b[1;32m    271\u001b[0m     create_node()  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;66;03m# Receive\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m     task_ins \u001b[38;5;241m=\u001b[39m \u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m task_ins \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# Wait for 3s before asking again\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/CF_FL/lib/python3.12/site-packages/flwr/client/grpc_client/connection.py:118\u001b[0m, in \u001b[0;36mgrpc_connection.<locals>.receive\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreceive\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TaskIns:\n\u001b[0;32m--> 118\u001b[0m     server_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mserver_message_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TaskIns(\n\u001b[1;32m    120\u001b[0m         task_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4()),\n\u001b[1;32m    121\u001b[0m         group_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m         ),\n\u001b[1;32m    129\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/CF_FL/lib/python3.12/site-packages/grpc/_channel.py:542\u001b[0m, in \u001b[0;36m_Rendezvous.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/CF_FL/lib/python3.12/site-packages/grpc/_channel.py:959\u001b[0m, in \u001b[0;36m_MultiThreadedRendezvous._next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_response_ready\u001b[39m():\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mresponse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    955\u001b[0m         cygrpc\u001b[38;5;241m.\u001b[39mOperationType\u001b[38;5;241m.\u001b[39mreceive_message \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mdue\n\u001b[1;32m    956\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    957\u001b[0m     )\n\u001b[0;32m--> 959\u001b[0m \u001b[43m_common\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_response_ready\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mresponse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mresponse\n",
      "File \u001b[0;32m~/miniforge3/envs/CF_FL/lib/python3.12/site-packages/grpc/_common.py:156\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(wait_fn, wait_complete_fn, timeout, spin_cb)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m wait_complete_fn():\n\u001b[0;32m--> 156\u001b[0m         \u001b[43m_wait_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAXIMUM_WAIT_TIMEOUT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspin_cb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m timeout\n",
      "File \u001b[0;32m~/miniforge3/envs/CF_FL/lib/python3.12/site-packages/grpc/_common.py:116\u001b[0m, in \u001b[0;36m_wait_once\u001b[0;34m(wait_fn, timeout, spin_cb)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wait_once\u001b[39m(\n\u001b[1;32m    112\u001b[0m     wait_fn: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mbool\u001b[39m],\n\u001b[1;32m    113\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[1;32m    114\u001b[0m     spin_cb: Optional[Callable[[], \u001b[38;5;28;01mNone\u001b[39;00m]],\n\u001b[1;32m    115\u001b[0m ):\n\u001b[0;32m--> 116\u001b[0m     \u001b[43mwait_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spin_cb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m         spin_cb()\n",
      "File \u001b[0;32m~/miniforge3/envs/CF_FL/lib/python3.12/threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 359\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start the training\n",
    "# model and history folder\n",
    "model = utils.models[args.model]\n",
    "train_fn = utils.trainings[args.model]\n",
    "evaluate_fn = utils.evaluations[args.model]\n",
    "plot_fn = utils.plot_functions[args.model]\n",
    "config = utils.config_tests[args.dataset][args.model]\n",
    "\n",
    "# check if metrics.csv exists otherwise delete it\n",
    "utils.check_and_delete_metrics_file(config['history_folder'] + f\"malicious_client_{args.data_type}_{args.attack_type}_{args.id}\", question=False)\n",
    "\n",
    "# check gpu and set manual seed\n",
    "device = utils.check_gpu(manual_seed=True)\n",
    "\n",
    "# load data\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, num_examples = utils.load_data_malicious(\n",
    "    client_id=str(args.id), device=device, type=args.data_type, dataset=args.dataset, attack_type=args.attack_type)\n",
    "\n",
    "# Model\n",
    "model = model(config=config).to(device)\n",
    "\n",
    "# Optimizer and Loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=config[\"learning_rate\"], momentum=0.9)\n",
    "\n",
    "# Start Flower client\n",
    "client = FlowerClient(model, X_train, y_train, X_val, y_val, optimizer, num_examples, args.id, args.data_type,\n",
    "                        train_fn, evaluate_fn, args.attack_type, config).to_client()\n",
    "fl.client.start_client(server_address=\"[::]:8098\", client=client) # local host\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Honest client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraies\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import utils\n",
    "import flwr as fl\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "# Define Flower client )\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, X_train, y_train, X_val, y_val, optimizer, num_examples, \n",
    "                 client_id, data_type, train_fn, evaluate_fn, config_model):\n",
    "        self.model = model\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        self.optimizer = optimizer\n",
    "        self.num_examples = num_examples\n",
    "        self.client_id = client_id\n",
    "        self.data_type = data_type\n",
    "        self.train_fn = train_fn\n",
    "        self.evaluate_fn = evaluate_fn\n",
    "        self.history_folder = config_model['history_folder']\n",
    "        self.config = config_model\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        self.model.set_client_id(self.client_id)\n",
    "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        try: \n",
    "            self.set_parameters(parameters)\n",
    "            model_trained, train_loss, val_loss, acc, acc_prime, acc_val, _ = self.train_fn(\n",
    "                self.model, self.loss_fn, self.optimizer, self.X_train, self.y_train, \n",
    "                self.X_val, self.y_val, n_epochs=config[\"local_epochs\"], print_info=False, config=self.config)\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during training of Honest client {self.client_id}: {e}, returning model with error\") \n",
    "        \n",
    "        return self.get_parameters(config), self.num_examples[\"trainset\"], {}\n",
    "    \n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        if self.model.__class__.__name__ == \"Predictor\":\n",
    "            try:\n",
    "                loss, accuracy = utils.evaluate_predictor(self.model, self.X_val, self.y_val, self.loss_fn, config=self.config)\n",
    "                # save loss and accuracy client\n",
    "                utils.save_client_metrics(config[\"current_round\"], loss, accuracy, 0, client_id=self.client_id,\n",
    "                                        data_type=self.data_type, tot_rounds=config['tot_rounds'], history_folder=self.history_folder)\n",
    "                return float(loss), self.num_examples[\"valset\"], {\"accuracy\": float(accuracy), \"mean_distance\": float(0), \"validity\": float(0)}\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred during inference of client {self.client_id}: {e}, returning same zero metrics\") \n",
    "                return float(10000), self.num_examples[\"valset\"], {\"accuracy\": float(0), \"mean_distance\": float(10000), \"validity\": float(0)}\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                loss, accuracy, validity, mean_proximity, hamming_distance, euclidian_distance, iou, variability = self.evaluate_fn(self.model, self.X_val, self.y_val, self.loss_fn, self.X_train, self.y_train, config=self.config)\n",
    "                # save loss and accuracy client\n",
    "                utils.save_client_metrics(config[\"current_round\"], loss, accuracy, validity, mean_proximity, hamming_distance, euclidian_distance, iou, variability,\n",
    "                                        self.client_id, self.data_type, config['tot_rounds'], self.history_folder)\n",
    "                return float(loss), self.num_examples[\"valset\"], {\"accuracy\": float(accuracy), \"proximity\": float(mean_proximity), \"validity\": float(validity),\n",
    "                                                                \"hamming_distance\": float(hamming_distance), \"euclidian_distance\": float(euclidian_distance),\n",
    "                                                                \"iou\": float(iou), \"variability\": float(variability)}\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred during inference of client {self.client_id}: {e}, returning same zero metrics\") \n",
    "                return float(10000), self.num_examples[\"valset\"], {\"accuracy\": float(0), \"proximity\": float(10000), \"validity\": float(0),\n",
    "                                                                \"hamming_distance\": float(10000), \"euclidian_distance\": float(10000),\n",
    "                                                                \"iou\": float(0), \"variability\": float(0)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the arguments directly in the notebook\n",
    "class Args:\n",
    "    id = 1  # Example: Set the id to 1 (adjust as needed, within range 1-100)\n",
    "    data_type = '2cluster'  # Choose between 'random', 'cluster', '2cluster'\n",
    "    dataset = 'diabetes'  # Choose between 'diabetes', 'breast', 'synthetic', 'mnist', 'cifar10'\n",
    "    model = 'net'  # Choose between 'net', 'vcnet', 'predictor'\n",
    "\n",
    "# Instantiate the Args class\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-28 14:50:22,989 | grpc.py:52 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flwr 2024-08-28 14:50:23,002 | connection.py:42 | ChannelConnectivity.IDLE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-28 14:50:23,211 | connection.py:141 | gRPC channel closed\n"
     ]
    },
    {
     "ename": "_MultiThreadedRendezvous",
     "evalue": "<_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"failed to connect to all addresses; last error: UNKNOWN: ipv6:%5B::%5D:8098: Failed to connect to remote host: Connection refused\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"failed to connect to all addresses; last error: UNKNOWN: ipv6:%5B::%5D:8098: Failed to connect to remote host: Connection refused\", grpc_status:14, created_time:\"2024-08-28T14:50:23.004429+02:00\"}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_MultiThreadedRendezvous\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Start Flower client\u001b[39;00m\n\u001b[1;32m     26\u001b[0m client \u001b[38;5;241m=\u001b[39m FlowerClient(model, X_train, y_train, X_val, y_val, optimizer, num_examples, args\u001b[38;5;241m.\u001b[39mid, args\u001b[38;5;241m.\u001b[39mdata_type,\n\u001b[1;32m     27\u001b[0m                         train_fn, evaluate_fn, config)\u001b[38;5;241m.\u001b[39mto_client()\n\u001b[0;32m---> 28\u001b[0m \u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[::]:8098\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# local host\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# read saved data and plot\u001b[39;00m\n\u001b[1;32m     31\u001b[0m plot_fn(args\u001b[38;5;241m.\u001b[39mid, args\u001b[38;5;241m.\u001b[39mdata_type, config, show\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/CF_FL/lib/python3.12/site-packages/flwr/client/app.py:275\u001b[0m, in \u001b[0;36mstart_client\u001b[0;34m(server_address, load_callable_fn, client_fn, client, grpc_max_message_length, root_certificates, insecure, transport)\u001b[0m\n\u001b[1;32m    271\u001b[0m     create_node()  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;66;03m# Receive\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m     task_ins \u001b[38;5;241m=\u001b[39m \u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m task_ins \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# Wait for 3s before asking again\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/CF_FL/lib/python3.12/site-packages/flwr/client/grpc_client/connection.py:118\u001b[0m, in \u001b[0;36mgrpc_connection.<locals>.receive\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreceive\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TaskIns:\n\u001b[0;32m--> 118\u001b[0m     server_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mserver_message_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TaskIns(\n\u001b[1;32m    120\u001b[0m         task_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4()),\n\u001b[1;32m    121\u001b[0m         group_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m         ),\n\u001b[1;32m    129\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/CF_FL/lib/python3.12/site-packages/grpc/_channel.py:542\u001b[0m, in \u001b[0;36m_Rendezvous.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/CF_FL/lib/python3.12/site-packages/grpc/_channel.py:951\u001b[0m, in \u001b[0;36m_MultiThreadedRendezvous._next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m()\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_response_ready\u001b[39m():\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mresponse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    955\u001b[0m         cygrpc\u001b[38;5;241m.\u001b[39mOperationType\u001b[38;5;241m.\u001b[39mreceive_message \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mdue\n\u001b[1;32m    956\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    957\u001b[0m     )\n",
      "\u001b[0;31m_MultiThreadedRendezvous\u001b[0m: <_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"failed to connect to all addresses; last error: UNKNOWN: ipv6:%5B::%5D:8098: Failed to connect to remote host: Connection refused\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"failed to connect to all addresses; last error: UNKNOWN: ipv6:%5B::%5D:8098: Failed to connect to remote host: Connection refused\", grpc_status:14, created_time:\"2024-08-28T14:50:23.004429+02:00\"}\"\n>"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "# model and history folder\n",
    "model = utils.models[args.model]\n",
    "train_fn = utils.trainings[args.model]\n",
    "evaluate_fn = utils.evaluations[args.model]\n",
    "plot_fn = utils.plot_functions[args.model]\n",
    "config = utils.config_tests[args.dataset][args.model]\n",
    "\n",
    "# check if metrics.csv exists otherwise delete it\n",
    "utils.check_and_delete_metrics_file(config['history_folder'] + f\"client_{args.data_type}_{args.id}\", question=False)\n",
    "\n",
    "# check gpu and set manual seed\n",
    "device = utils.check_gpu(manual_seed=True)\n",
    "\n",
    "# load data\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, num_examples = utils.load_data(\n",
    "    client_id=str(args.id), device=device, type=args.data_type, dataset=args.dataset)\n",
    "\n",
    "# Model\n",
    "model = model(config=config).to(device)\n",
    "\n",
    "# Optimizer and Loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=config[\"learning_rate\"], momentum=0.9)\n",
    "\n",
    "# Start Flower client\n",
    "client = FlowerClient(model, X_train, y_train, X_val, y_val, optimizer, num_examples, args.id, args.data_type,\n",
    "                        train_fn, evaluate_fn, config).to_client()\n",
    "fl.client.start_client(server_address=\"[::]:8098\", client=client) # local host\n",
    "\n",
    "# read saved data and plot\n",
    "plot_fn(args.id, args.data_type, config, show=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CF_FL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
