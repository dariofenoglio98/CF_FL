{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple-machines Federated Learning\n",
    "Choose your role! We need one server, one/two malicious clients, and several honest clients.\n",
    "\n",
    "To do:\n",
    "- Create a conda environment ```conda env create -f environment.yml``` (or manually and then run ```pip install -r requirements.txt```)\n",
    "- Run ```ifconfig``` to find your IP address, and check under en0 (for Wi-Fi) or en7 (for Ethernet/cable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_ip_address = \"10.21.13.79\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "# Get the current working directory, remove last, and change the current working directory to the parent directory\n",
    "current_path = os.getcwd()\n",
    "parent_path = os.path.dirname(current_path) +'/data'\n",
    "os.chdir(parent_path)\n",
    " \n",
    "# Create CIFAR-10 dataset\n",
    "print(\"\\033[93m Create CIFAR-10\\033[00m\")\n",
    "script_path = os.path.join(parent_path, 'cifar_creation.py')\n",
    "!python $script_path\n",
    " \n",
    "# Create MNIST dataset\n",
    "print(\"\\033[93m Create MNIST\\033[00m\")\n",
    "script_path = os.path.join(parent_path, 'mnist_creation.py')\n",
    "!python $script_path\n",
    " \n",
    "# Split client datasets\n",
    "parent_path = os.path.dirname(current_path)\n",
    "os.chdir(parent_path)\n",
    "print(\"\\033[93m Split client datasets\\033[00m\")\n",
    "script_path = os.path.join(parent_path, 'data/client_split.py')\n",
    "!python $script_path --seed 1 --n_clients 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Server** - Federated Behavioural Planes\n",
    "Otherwise from terminal: ```python server_FBPs.py --rounds \"50\" --data_type \"2cluster\" --dataset \"diabetes\" --model \"net\" --pers \"0\" --n_clients \"3\" --n_attackers \"0\" --attack_type \"DP_flip\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries and functions\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Union, Optional, Dict\n",
    "from flwr.common import Parameters, Scalar, Metrics\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.common import FitRes\n",
    "import argparse\n",
    "import torch\n",
    "import utils\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Config_client\n",
    "def fit_config(server_round: int):\n",
    "    \"\"\"Return training configuration dict for each round.\"\"\"\n",
    "    config = {\n",
    "        \"current_round\": server_round,\n",
    "        \"local_epochs\": 2,\n",
    "        \"tot_rounds\": 20,\n",
    "    }\n",
    "    return config\n",
    "\n",
    "# Custom weighted average function\n",
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    validities = [num_examples * m[\"validity\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples), \"validity\": sum(validities) / sum(examples)}\n",
    "\n",
    "# Custom strategy to save model after each round\n",
    "class SaveModelStrategy(fl.server.strategy.FedAvg):\n",
    "    def __init__(self, model, data_type, checkpoint_folder, dataset, fold, model_config, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.model = model\n",
    "        self.data_type = data_type\n",
    "        self.checkpoint_folder = checkpoint_folder\n",
    "        self.dataset = dataset\n",
    "        self.model_config = model_config\n",
    "        self.fold = fold\n",
    "\n",
    "        # read data for testing\n",
    "        self.X_test, self.y_test = utils.load_data_test(data_type=self.data_type, dataset=self.dataset)\n",
    "\n",
    "        if self.dataset == 'diabetes':\n",
    "            # randomly pick N samples <= 10605\n",
    "            idx = np.random.choice(len(self.X_test), 300, replace=False)\n",
    "            self.X_test = self.X_test[idx]\n",
    "            self.y_test = self.y_test[idx]\n",
    "        elif self.dataset == 'breast':\n",
    "            # randomly pick N samples <= 89\n",
    "            idx = np.random.choice(len(self.X_test), 88, replace=False)\n",
    "            self.X_test = self.X_test[idx]\n",
    "            self.y_test = self.y_test[idx] \n",
    "        elif self.dataset == 'synthetic':\n",
    "            # randomly pick N samples <= 938\n",
    "            idx = np.random.choice(len(self.X_test), 300, replace=False)\n",
    "            self.X_test = self.X_test[idx]\n",
    "            self.y_test = self.y_test[idx]\n",
    "        elif self.dataset == 'mnist':\n",
    "            # randomly pick N samples <= 938\n",
    "            idx = np.random.choice(len(self.X_test), 300, replace=False)\n",
    "            self.X_test = self.X_test[idx]\n",
    "            self.y_test = self.y_test[idx] \n",
    "        elif self.dataset == 'cifar10':\n",
    "            # randomly pick N samples <= 938\n",
    "            idx = np.random.choice(len(self.X_test), 280, replace=False)\n",
    "            self.X_test = self.X_test[idx]\n",
    "            self.y_test = self.y_test[idx]      \n",
    "        \n",
    "        print(f\"Used Size Server-Test Set: {self.X_test.shape}\")\n",
    "\n",
    "        # create folder if not exists\n",
    "        if not os.path.exists(self.checkpoint_folder + f\"{self.data_type}\"):\n",
    "            os.makedirs(self.checkpoint_folder + f\"{self.data_type}\")\n",
    "\n",
    "    # Override aggregate_fit method to add saving functionality\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[fl.server.client_proxy.ClientProxy, fl.common.FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate model weights using weighted average and store checkpoint\"\"\"\n",
    "\n",
    "        # Perform evaluation on the server side on each single client after local training for each clients evaluate the model\n",
    "        client_data = {}\n",
    "        for client, fit_res in results:\n",
    "            # Load model\n",
    "            params = fl.common.parameters_to_ndarrays(fit_res.parameters)\n",
    "            params_dict = zip(self.model.state_dict().keys(), params)\n",
    "            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "            cid = int(np.round(state_dict['cid'].item()))\n",
    "            self.model.load_state_dict(state_dict, strict=True)\n",
    "            # Evaluate the model\n",
    "            try:\n",
    "                client_metrics = utils.server_side_evaluation(self.X_test, self.y_test, model=self.model, config=self.model_config)\n",
    "                client_data[cid] = client_metrics\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred during server-side evaluation of client {cid}: {e}, returning zero metrics\") \n",
    "\n",
    "        # Planes construction\n",
    "        utils.creation_planes_FBPs(client_data, server_round, self.data_type, self.dataset, self.model_config, self.fold)\n",
    "        \n",
    "        # Call aggregate_fit from base class (FedAvg) to aggregate parameters and metrics\n",
    "        aggregated_parameters, aggregated_metrics = super().aggregate_fit(server_round, results, failures) # aggregated_metrics from aggregate_fit is empty except if i pass fit_metrics_aggregation_fn\n",
    "\n",
    "        # Save model\n",
    "        if aggregated_parameters is not None:\n",
    "\n",
    "            print(f\"Saving round {server_round} aggregated_parameters...\")\n",
    "            # Convert `Parameters` to `List[np.ndarray]`\n",
    "            aggregated_ndarrays: List[np.ndarray] = fl.common.parameters_to_ndarrays(aggregated_parameters)\n",
    "            # Convert `List[np.ndarray]` to PyTorch`state_dict`\n",
    "            params_dict = zip(self.model.state_dict().keys(), aggregated_ndarrays)\n",
    "            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "            self.model.load_state_dict(state_dict, strict=True)\n",
    "            # Save the model\n",
    "            torch.save(self.model.state_dict(), self.checkpoint_folder + f\"{self.data_type}/model_round_{server_round}.pth\")\n",
    "        \n",
    "        return aggregated_parameters, aggregated_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup arguments and initialize strategy\n",
    "class Args:\n",
    "    rounds = 20\n",
    "    data_type = '2cluster' # Choose between: '2cluster', 'random' (i.e., non-IID and IID)\n",
    "    dataset = 'diabetes' # Choose between: 'diabetes', 'breast', 'synthetic', 'mnist', 'cifar10'\n",
    "    model = 'net' # Choose between: 'net', 'vcnet'\n",
    "    pers = 0 \n",
    "    n_clients = 3\n",
    "    n_attackers = 1\n",
    "    attack_type = 'DP_flip' # Choose between: 'DP_flip', 'DP_inverted_loss', 'MP_noise', 'MP_gradient'\n",
    "    fold = 0\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-28 19:08:13,999 | app.py:163 | Starting Flower server, config: ServerConfig(num_rounds=20, round_timeout=None)\n",
      "INFO flwr 2024-08-28 19:08:14,013 | app.py:176 | Flower ECE: gRPC server running (20 rounds), SSL is disabled\n",
      "INFO flwr 2024-08-28 19:08:14,014 | server.py:89 | Initializing global parameters\n",
      "INFO flwr 2024-08-28 19:08:14,015 | server.py:276 | Requesting initial parameters from one random client\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Size Server-Test Set: torch.Size([300, 21])\n",
      "Num. min fit clients: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-28 19:08:18,849 | server.py:280 | Received initial parameters from one random client\n",
      "INFO flwr 2024-08-28 19:08:18,850 | server.py:91 | Evaluating initial parameters\n",
      "INFO flwr 2024-08-28 19:08:18,851 | server.py:104 | FL starting\n",
      "DEBUG flwr 2024-08-28 19:08:23,334 | server.py:222 | fit_round 1: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-08-28 19:08:24,063 | server.py:236 | fit_round 1 received 4 results and 0 failures\n",
      "WARNING flwr 2024-08-28 19:08:24,469 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2024-08-28 19:08:24,502 | server.py:173 | evaluate_round 1: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 1 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-28 19:08:24,736 | server.py:187 | evaluate_round 1 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:24,736 | server.py:222 | fit_round 2: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-08-28 19:08:24,986 | server.py:236 | fit_round 2 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:25,226 | server.py:173 | evaluate_round 2: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 2 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-28 19:08:25,408 | server.py:187 | evaluate_round 2 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:25,409 | server.py:222 | fit_round 3: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-08-28 19:08:25,671 | server.py:236 | fit_round 3 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:25,903 | server.py:173 | evaluate_round 3: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 3 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-28 19:08:26,108 | server.py:187 | evaluate_round 3 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:26,108 | server.py:222 | fit_round 4: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-08-28 19:08:26,418 | server.py:236 | fit_round 4 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:26,660 | server.py:173 | evaluate_round 4: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 4 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-28 19:08:26,848 | server.py:187 | evaluate_round 4 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:26,849 | server.py:222 | fit_round 5: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-08-28 19:08:27,118 | server.py:236 | fit_round 5 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:27,431 | server.py:173 | evaluate_round 5: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-08-28 19:08:27,550 | server.py:187 | evaluate_round 5 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:27,551 | server.py:222 | fit_round 6: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 5 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-28 19:08:27,805 | server.py:236 | fit_round 6 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:28,052 | server.py:173 | evaluate_round 6: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-08-28 19:08:28,186 | server.py:187 | evaluate_round 6 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:28,187 | server.py:222 | fit_round 7: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 6 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-28 19:08:28,430 | server.py:236 | fit_round 7 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:28,669 | server.py:173 | evaluate_round 7: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 7 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-28 19:08:28,869 | server.py:187 | evaluate_round 7 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:28,869 | server.py:222 | fit_round 8: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-08-28 19:08:29,100 | server.py:236 | fit_round 8 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:29,330 | server.py:173 | evaluate_round 8: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-08-28 19:08:29,456 | server.py:187 | evaluate_round 8 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:29,457 | server.py:222 | fit_round 9: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 8 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-28 19:08:29,688 | server.py:236 | fit_round 9 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:29,931 | server.py:173 | evaluate_round 9: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-08-28 19:08:30,100 | server.py:187 | evaluate_round 9 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:30,101 | server.py:222 | fit_round 10: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 9 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-28 19:08:30,344 | server.py:236 | fit_round 10 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:30,588 | server.py:173 | evaluate_round 10: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-08-28 19:08:30,731 | server.py:187 | evaluate_round 10 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:30,731 | server.py:222 | fit_round 11: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 10 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-28 19:08:30,970 | server.py:236 | fit_round 11 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:31,220 | server.py:173 | evaluate_round 11: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-08-28 19:08:31,338 | server.py:187 | evaluate_round 11 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:31,338 | server.py:222 | fit_round 12: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 11 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-28 19:08:31,585 | server.py:236 | fit_round 12 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:31,832 | server.py:173 | evaluate_round 12: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-08-28 19:08:31,954 | server.py:187 | evaluate_round 12 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:31,955 | server.py:222 | fit_round 13: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 12 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-28 19:08:32,180 | server.py:236 | fit_round 13 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:32,438 | server.py:173 | evaluate_round 13: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-08-28 19:08:32,575 | server.py:187 | evaluate_round 13 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:32,575 | server.py:222 | fit_round 14: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 13 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-28 19:08:32,803 | server.py:236 | fit_round 14 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:33,052 | server.py:173 | evaluate_round 14: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-08-28 19:08:33,174 | server.py:187 | evaluate_round 14 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:33,175 | server.py:222 | fit_round 15: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 14 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-28 19:08:33,410 | server.py:236 | fit_round 15 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:33,650 | server.py:173 | evaluate_round 15: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-08-28 19:08:33,786 | server.py:187 | evaluate_round 15 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:33,786 | server.py:222 | fit_round 16: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 15 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-28 19:08:34,038 | server.py:236 | fit_round 16 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:34,289 | server.py:173 | evaluate_round 16: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-08-28 19:08:34,419 | server.py:187 | evaluate_round 16 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:34,419 | server.py:222 | fit_round 17: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 16 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-28 19:08:34,663 | server.py:236 | fit_round 17 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:34,903 | server.py:173 | evaluate_round 17: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-08-28 19:08:35,008 | server.py:187 | evaluate_round 17 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:35,008 | server.py:222 | fit_round 18: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 17 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-28 19:08:35,282 | server.py:236 | fit_round 18 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:35,537 | server.py:173 | evaluate_round 18: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 18 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-28 19:08:35,735 | server.py:187 | evaluate_round 18 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:35,736 | server.py:222 | fit_round 19: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-08-28 19:08:35,979 | server.py:236 | fit_round 19 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:36,222 | server.py:173 | evaluate_round 19: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-08-28 19:08:36,327 | server.py:187 | evaluate_round 19 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:36,328 | server.py:222 | fit_round 20: strategy sampled 4 clients (out of 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 19 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-28 19:08:36,592 | server.py:236 | fit_round 20 received 4 results and 0 failures\n",
      "DEBUG flwr 2024-08-28 19:08:36,846 | server.py:173 | evaluate_round 20: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-08-28 19:08:36,976 | server.py:187 | evaluate_round 20 received 4 results and 0 failures\n",
      "INFO flwr 2024-08-28 19:08:36,977 | server.py:153 | FL finished in 18.12536312500015\n",
      "INFO flwr 2024-08-28 19:08:36,977 | app.py:226 | app_fit: losses_distributed [(1, 0.7020916417697387), (2, 0.6540282339326978), (3, 0.6247866404807474), (4, 0.6129413263013461), (5, 0.6090742059293173), (6, 0.6089047145030004), (7, 0.6151913188443513), (8, 0.6280088540971644), (9, 0.6404725683955695), (10, 0.6464385409445901), (11, 0.64452889553831), (12, 0.6366023310604371), (13, 0.626501913054513), (14, 0.6176304238622687), (15, 0.6115855304483562), (16, 0.6090301754880347), (17, 0.6083610691032385), (18, 0.6080159882469753), (19, 0.6061153889927859), (20, 0.6018800945758611)]\n",
      "INFO flwr 2024-08-28 19:08:36,977 | app.py:227 | app_fit: metrics_distributed_fit {}\n",
      "INFO flwr 2024-08-28 19:08:36,978 | app.py:228 | app_fit: metrics_distributed {'accuracy': [(1, 0.38429571984112526), (2, 0.6938976461128091), (3, 0.6938976461128091), (4, 0.6938976461128091), (5, 0.6938976461128091), (6, 0.6938976461128091), (7, 0.6938976461128091), (8, 0.6938976461128091), (9, 0.694007008811516), (10, 0.6989282665942076), (11, 0.7004593033033928), (12, 0.6988188838838801), (13, 0.6958661336754877), (14, 0.6948818927166343), (15, 0.6953193332775058), (16, 0.6955380582512207), (17, 0.6996937856886435), (18, 0.7030839824288014), (19, 0.7119422615004649), (20, 0.7119422521334621)], 'validity': [(1, 0.4199475109942212), (2, 0.0), (3, 0.0), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.0), (8, 0.0), (9, 0.0007655292966652397), (10, 0.0189195095418039), (11, 0.032261591835708495), (12, 0.018482064143432692), (13, 0.008530183271048647), (14, 0.004483814399436031), (15, 0.00404636909395264), (16, 0.008967628582235676), (17, 0.03127733995153692), (18, 0.07425634154099857), (19, 0.12434383040116423), (20, 0.15266841366782796)]}\n",
      "INFO flwr 2024-08-28 19:08:36,978 | app.py:229 | app_fit: losses_centralized []\n",
      "INFO flwr 2024-08-28 19:08:36,979 | app.py:230 | app_fit: metrics_centralized {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 20 aggregated_parameters...\n",
      "\u001b[90mTraining time: 0.38 minutes\u001b[0m\n",
      "Saving metrics to as .json in histories folder...\n",
      "\n",
      "\u001b[1;34mServer Side\u001b[0m \n",
      "Minimum Loss occurred at round 20 with a loss value of 0.6018800945758611 \n",
      "Maximum Accuracy occurred at round 19 with an accuracy value of 0.7119422615004649 \n",
      "Maximum Validity occurred at round 1 with a validity value of 0.4199475109942212\n",
      "\n",
      "\n",
      "\n",
      "\u001b[95mVisualizing the results of the best model (2cluster) on the test set (diabetes)...\u001b[0m\n",
      "--------------------------\n",
      "Patient 1: Diabetes level = 1\n",
      "Features to change to make the Diabetes level = 0\n",
      "Feature: HighBP from 1.0000 to 0.0000\n",
      "Feature: BMI from 35.0000 to 49.0000\n",
      "Feature: HeartDiseaseorAttack from 1.0000 to 0.0000\n",
      "Feature: GenHlth from 5.0000 to 2.0000\n",
      "Feature: MentHlth from 0.0000 to -1.0000\n",
      "Feature: PhysHlth from 30.0000 to 10.0000\n",
      "Feature: DiffWalk from 1.0000 to 0.0000\n",
      "Feature: Age from 11.0000 to 13.0000\n",
      "Feature: Education from 4.0000 to 5.0000\n",
      "Feature: Income from 5.0000 to 7.0000\n",
      "--------------------------\n",
      "Patient 2: Diabetes level = 1\n",
      "Features to change to make the Diabetes level = 0\n",
      "Feature: HighChol from 1.0000 to 0.0000\n",
      "Feature: BMI from 41.0000 to 46.0000\n",
      "Feature: Smoker from 1.0000 to 0.0000\n",
      "Feature: Stroke from 1.0000 to 0.0000\n",
      "Feature: HeartDiseaseorAttack from 1.0000 to 0.0000\n",
      "Feature: PhysActivity from 0.0000 to 1.0000\n",
      "Feature: Fruits from 0.0000 to 1.0000\n",
      "Feature: Veggies from 0.0000 to 1.0000\n",
      "Feature: GenHlth from 5.0000 to 4.0000\n",
      "Feature: MentHlth from 0.0000 to 3.0000\n",
      "Feature: PhysHlth from 30.0000 to 7.0000\n",
      "Feature: DiffWalk from 1.0000 to 0.0000\n",
      "Feature: Sex from 1.0000 to 0.0000\n",
      "Feature: Age from 10.0000 to 13.0000\n",
      "Feature: Education from 5.0000 to 6.0000\n",
      "Feature: Income from 8.0000 to 6.0000\n",
      "--------------------------\n",
      "Patient 3: Diabetes level = 1\n",
      "Features to change to make the Diabetes level = 0\n",
      "Feature: BMI from 40.0000 to 32.0000\n",
      "Feature: PhysActivity from 0.0000 to 1.0000\n",
      "Feature: Fruits from 0.0000 to 1.0000\n",
      "Feature: Veggies from 0.0000 to 1.0000\n",
      "Feature: MentHlth from 0.0000 to -1.0000\n",
      "Feature: PhysHlth from 28.0000 to 6.0000\n",
      "Feature: DiffWalk from 1.0000 to 0.0000\n",
      "Feature: Age from 11.0000 to 9.0000\n",
      "Feature: Education from 5.0000 to 6.0000\n",
      "Feature: Income from 5.0000 to 6.0000\n",
      "--------------------------\n",
      "Patient 4: Diabetes level = 1\n",
      "Features to change to make the Diabetes level = 0\n",
      "Feature: BMI from 30.0000 to 33.0000\n",
      "Feature: HeartDiseaseorAttack from 1.0000 to 0.0000\n",
      "Feature: Fruits from 1.0000 to 0.0000\n",
      "Feature: Veggies from 1.0000 to 0.0000\n",
      "Feature: GenHlth from 5.0000 to 3.0000\n",
      "Feature: MentHlth from 10.0000 to -1.0000\n",
      "Feature: PhysHlth from 20.0000 to 6.0000\n",
      "Feature: Sex from 1.0000 to 0.0000\n",
      "Feature: Age from 10.0000 to 6.0000\n",
      "Feature: Education from 6.0000 to 5.0000\n",
      "--------------------------\n",
      "Patient 5: Diabetes level = 1\n",
      "Features to change to make the Diabetes level = 0\n",
      "Feature: BMI from 34.0000 to 36.0000\n",
      "Feature: Smoker from 1.0000 to 0.0000\n",
      "Feature: PhysActivity from 1.0000 to 0.0000\n",
      "Feature: Fruits from 0.0000 to 1.0000\n",
      "Feature: Veggies from 0.0000 to 1.0000\n",
      "Feature: GenHlth from 4.0000 to 3.0000\n",
      "Feature: MentHlth from 5.0000 to 11.0000\n",
      "Feature: PhysHlth from 21.0000 to 2.0000\n",
      "Feature: DiffWalk from 1.0000 to 0.0000\n",
      "Feature: Age from 10.0000 to 6.0000\n",
      "Feature: Education from 4.0000 to 6.0000\n",
      "Feature: Income from 4.0000 to 8.0000\n",
      "--------------------------\n",
      "Patient 6: Diabetes level = 1\n",
      "Features to change to make the Diabetes level = 0\n",
      "Feature: Smoker from 1.0000 to 0.0000\n",
      "Feature: PhysActivity from 0.0000 to 1.0000\n",
      "Feature: Veggies from 0.0000 to 1.0000\n",
      "Feature: GenHlth from 5.0000 to 3.0000\n",
      "Feature: MentHlth from 5.0000 to -1.0000\n",
      "Feature: PhysHlth from 20.0000 to 7.0000\n",
      "Feature: DiffWalk from 1.0000 to 0.0000\n",
      "Feature: Age from 12.0000 to 8.0000\n",
      "Feature: Education from 4.0000 to 6.0000\n",
      "Feature: Income from 4.0000 to 7.0000\n",
      "\n",
      "\u001b[1;91mEvaluation on General Testing Set - Server\u001b[0m\n",
      "Counterfactual validity: 0.1006\n",
      "Counterfactual accuracy: 0.5691\n",
      "Counterfactual loss: 6.0694\n",
      "\u001b[1;32mDistance Evaluation - Counterfactual: Training Set\u001b[0m\n",
      "Mean distance with all training sets (proximity, hamming proximity, relative proximity): 14.2313, 5.3399, 0.9597\n",
      "Mean distance with training set 1 (proximity, hamming proximity, relative proximity): 25.8889, 5.8112, 0.9998\n",
      "Mean distance with training set 2 (proximity, hamming proximity, relative proximity): 15.5923, 5.2619, 0.9677\n",
      "Mean distance with training set 3 (proximity, hamming proximity, relative proximity): 14.6193, 4.8682, 0.9931\n",
      "\u001b[1;32mExtra metrics Evaluation - Counterfactual: Training Set\u001b[0m\n",
      "Hamming Distance: 9.35\n",
      "Euclidean Distance: 30.10\n",
      "Relative Distance: 4.78\n",
      "Intersection over Union: 0.00\n",
      "Variability: 0.95 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  9.32it/s]\n",
      "100%|██████████| 20/20 [00:02<00:00,  8.52it/s]\n",
      "100%|██████████| 20/20 [00:02<00:00,  9.88it/s]\n",
      "100%|██████████| 20/20 [00:02<00:00,  8.57it/s]\n",
      "100%|██████████| 20/20 [00:01<00:00, 11.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\n",
      "You were lucky!\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Start server\n",
    "if not os.path.exists(f\"results/{args.model}/{args.dataset}/{args.data_type}/{args.fold}\"):\n",
    "    os.makedirs(f\"results/{args.model}/{args.dataset}/{args.data_type}/{args.fold}\")\n",
    "else:\n",
    "    # remove the directory and create a new one\n",
    "    os.system(f\"rm -r results/{args.model}/{args.dataset}/{args.data_type}/{args.fold}\")\n",
    "    os.makedirs(f\"results/{args.model}/{args.dataset}/{args.data_type}/{args.fold}\")\n",
    "\n",
    "# model and history folder\n",
    "model = utils.models[args.model]\n",
    "config = utils.config_tests[args.dataset][args.model]\n",
    "\n",
    "# Define strategy\n",
    "strategy = SaveModelStrategy(\n",
    "    model=model(config=config), # model to be trained\n",
    "    min_fit_clients=args.n_clients+args.n_attackers, # Never sample less than 10 clients for training\n",
    "    min_evaluate_clients=args.n_clients+args.n_attackers,  # Never sample less than 5 clients for evaluation\n",
    "    min_available_clients=args.n_clients+args.n_attackers, # Wait until all 10 clients are available\n",
    "    fraction_fit=1.0, # Sample 100 % of available clients for training\n",
    "    fraction_evaluate=1.0, # Sample 100 % of available clients for evaluation\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,\n",
    "    on_evaluate_config_fn=fit_config,\n",
    "    on_fit_config_fn=fit_config,\n",
    "    data_type=args.data_type,\n",
    "    checkpoint_folder=config['checkpoint_folder'],\n",
    "    dataset=args.dataset,\n",
    "    fold=args.fold,\n",
    "    model_config=config,\n",
    ")\n",
    "\n",
    "print(f\"Num. min fit clients: {strategy.min_fit_clients}\")\n",
    "\n",
    "# Start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Start Flower server for three rounds of federated learning\n",
    "history = fl.server.start_server(\n",
    "    # server_address=\"0.0.0.0:8098\",   # 0.0.0.0 listens to all available interfaces\n",
    "    server_address=f\"{server_ip_address}:8098\",\n",
    "    config=fl.server.ServerConfig(num_rounds=args.rounds),\n",
    "    strategy=strategy,\n",
    ")\n",
    "\n",
    "# Print training time in minutes (grey color)\n",
    "training_time = (time.time() - start_time)/60\n",
    "print(f\"\\033[90mTraining time: {round(training_time, 2)} minutes\\033[0m\")\n",
    "time.sleep(1)\n",
    "\n",
    "# convert history to list\n",
    "loss = [k[1] for k in history.losses_distributed]\n",
    "accuracy = [k[1] for k in history.metrics_distributed['accuracy']]\n",
    "validity = [k[1] for k in history.metrics_distributed['validity']]\n",
    "\n",
    "# Save loss and accuracy to a file\n",
    "print(f\"Saving metrics to as .json in histories folder...\")\n",
    "# # check if folder exists and save metrics\n",
    "if not os.path.exists(config['history_folder'] + f\"server_{args.data_type}\"):\n",
    "    os.makedirs(config['history_folder'] + f\"server_{args.data_type}\")\n",
    "with open(config['history_folder'] + f'server_{args.data_type}/metrics_{args.rounds}_{args.attack_type}_{args.n_attackers}_none_{args.fold}.json', 'w') as f:\n",
    "    json.dump({'loss': loss, 'accuracy': accuracy, 'validity':validity}, f)\n",
    "\n",
    "# Single Plot\n",
    "best_loss_round, best_acc_round = utils.plot_loss_and_accuracy(args, loss, accuracy, validity, config=config, show=False)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "if args.model == 'predictor':\n",
    "    y_test_pred, accuracy = utils.evaluation_central_test_predictor(args, best_model_round=best_loss_round, config=config)\n",
    "    print(f\"Accuracy on test set: {accuracy}\")\n",
    "    df_excel = {}\n",
    "    df_excel['accuracy'] = [accuracy]\n",
    "    df_excel = pd.DataFrame(df_excel)\n",
    "    df_excel.to_excel(f\"results_fold_{args.fold}.xlsx\")\n",
    "else:\n",
    "    utils.evaluation_central_test(args, best_model_round=best_loss_round, model=model, config=config)\n",
    "    \n",
    "    # Evaluate distance with all training sets\n",
    "    df_excel = utils.evaluate_distance(args, best_model_round=best_loss_round, model_fn=model, config=config, spec_client_val=False, training_time=training_time)\n",
    "    if args.fold != 0:\n",
    "        df_excel.to_excel(f\"results_fold_{args.fold}.xlsx\")\n",
    "\n",
    "# personalization (now done on the server but can be uqually done on the client side) \n",
    "if args.pers == 1:\n",
    "    start_time = time.time()\n",
    "    # Personalization\n",
    "    print(\"\\n\\n\\n\\n\\033[94mPersonalization\\033[0m\")\n",
    "    df_excel_list = utils.personalization(args, model_fn=model, config=config, best_model_round=best_loss_round)\n",
    "    if args.fold != 0:\n",
    "        for i in range(args.n_clients):\n",
    "            print(f\"Saving results_fold_{args.fold}_personalization_{i+1}.xlsx\")\n",
    "            df_excel_list[i].to_excel(f\"results_fold_{args.fold}_personalization_{i+1}.xlsx\")\n",
    "\n",
    "    # Print training time in minutes (grey color)\n",
    "    print(f\"\\033[90mPersonalization time: {round((time.time() - start_time)/60, 2)} minutes\\033[0m\")\n",
    "\n",
    "# Create gif\n",
    "utils.create_gif(args, config)\n",
    "\n",
    "print(f\"\\033[92m\\nYou were lucky!\\033[00m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Malicious Client**\n",
    "Otherwise from the terminal: ```python malicious_client.py --id \"1\" --data_type \"2cluster\" --model \"net\" --dataset \"diabetes\" --attack_type 'DP_flip'```\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraies and functions\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import utils\n",
    "import flwr as fl\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "# Define Flower client\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, X_train, y_train, X_val, y_val, optimizer, num_examples, \n",
    "                 client_id, data_type, train_fn, evaluate_fn, attack_type, config_model):\n",
    "        self.model = model\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.loss_fn = utils.InvertedLoss() if attack_type==\"DP_inverted_loss\" else torch.nn.CrossEntropyLoss()\n",
    "        self.optimizer = optimizer\n",
    "        self.num_examples = num_examples\n",
    "        self.client_id = client_id \n",
    "        self.data_type = data_type\n",
    "        self.train_fn = train_fn\n",
    "        self.evaluate_fn = evaluate_fn\n",
    "        self.history_folder = config_model['history_folder']\n",
    "        self.config_model = config_model\n",
    "        self.attack_type = attack_type\n",
    "        self.saved_models = {} # Save the parameters of the previous rounds\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        params = []\n",
    "        for k, v in self.model.state_dict().items():\n",
    "            if k == 'cid':\n",
    "                params.append(np.array([self.client_id + 100]))\n",
    "                continue\n",
    "            if k == 'mask' or k=='binary_feature':\n",
    "                params.append(v.cpu().numpy())\n",
    "                continue\n",
    "            # Original parameters\n",
    "            if self.attack_type in [\"None\", \"DP_flip\", \"DP_random\", \"DP_inverted_loss\", \"DP_inverted_loss_cf\"]:\n",
    "                params.append(v.cpu().numpy())\n",
    "            # Mimic the actual parameter range by observing the mean and std of each parameter\n",
    "            elif self.attack_type == \"MP_random\":\n",
    "                v = v.cpu().numpy()\n",
    "                params.append(np.random.normal(loc=np.mean(v), scale=np.std(v), size=v.shape).astype(np.float32))\n",
    "            # Introducing random noise to the parameters\n",
    "            elif self.attack_type == \"MP_noise\":\n",
    "                v = v.cpu().numpy()\n",
    "                params.append(v + np.random.normal(0, 1.2*np.std(v), v.shape).astype(np.float32))   \n",
    "            # Gradient-based attack - flip the sign of the gradient and scale it by a factor [adaptation of Fall of Empires]\n",
    "            elif self.attack_type == \"MP_gradient\": # Fall of Empires\n",
    "                if config[\"current_round\"] == 1:\n",
    "                    params.append(v.cpu().numpy()) # Use the original parameters for the first round\n",
    "                    continue\n",
    "                else:\n",
    "                    epsilon = 0.1 # from 0 to 10 --- reverse gradient when epsilon is equal to learning rate\n",
    "                    learning_rate = 0.01\n",
    "                    prev_v = self.saved_models.get(config[\"current_round\"] - 1).get(k).cpu().numpy()\n",
    "                    current_v = v.cpu().numpy()\n",
    "                    gradient = (prev_v - current_v)/learning_rate # precisely mean gradients from all the other clients\n",
    "                    manipulated_param = current_v + epsilon * gradient  # apply gradient in the opposite direction\n",
    "                    params.append(manipulated_param.astype(np.float32))\n",
    "\n",
    "        return params\n",
    "    \n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "    \n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        if self.attack_type in [\"None\", \"DP_flip\", \"DP_random\", \"DP_inverted_loss\"]:\n",
    "            try:\n",
    "                model_trained, train_loss, val_loss, acc, acc_prime, acc_val, _ = self.train_fn(\n",
    "                    self.model, self.loss_fn, self.optimizer, self.X_train, self.y_train, \n",
    "                    self.X_val, self.y_val, n_epochs=config[\"local_epochs\"], print_info=False, config=self.config_model)\n",
    "            except Exception as e:\n",
    "                # print(f\"An error occurred during training of Malicious client: {e}, returning model with error\") \n",
    "                print(f\"An error occurred during training of Malicious client, returning model with error\") \n",
    "\n",
    "        elif self.attack_type in [\"DP_inverted_loss_cf\"]:\n",
    "            try:\n",
    "                model_trained, train_loss, val_loss, acc, acc_prime, acc_val, _ = self.train_fn(\n",
    "                    self.model, self.loss_fn, self.optimizer, self.X_train, self.y_train, \n",
    "                    self.X_val, self.y_val, n_epochs=config[\"local_epochs\"], print_info=False, config=self.config_model, inv_loss_cf=True)\n",
    "            except Exception as e:\n",
    "                # print(f\"An error occurred during training of Malicious client: {e}, returning model with error\") \n",
    "                print(f\"An error occurred during training of Malicious client, returning model with error\")\n",
    "\n",
    "        elif self.attack_type == \"MP_gradient\":\n",
    "            self.saved_models[config[\"current_round\"]] = {k: v.clone() for k, v in self.model.state_dict().items()}\n",
    "            # delede previous 3-rounds model\n",
    "            if config[\"current_round\"] > 3:\n",
    "                del self.saved_models[config[\"current_round\"]-3]\n",
    "        return self.get_parameters(config), self.num_examples[\"trainset\"], {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        if self.model.__class__.__name__ == \"Predictor\":\n",
    "            try:\n",
    "                loss, accuracy = utils.evaluate_predictor(self.model, self.X_val, self.y_val, self.loss_fn, config=self.config_model)\n",
    "                # save loss and accuracy client\n",
    "                utils.save_client_metrics(config[\"current_round\"], loss, accuracy, 0, client_id=self.client_id,\n",
    "                                        data_type=self.data_type, tot_rounds=config['tot_rounds'], history_folder=self.history_folder)\n",
    "                return float(loss), self.num_examples[\"valset\"], {\"accuracy\": float(accuracy), \"mean_distance\": float(0), \"validity\": float(0)}\n",
    "            except Exception as e:\n",
    "                #print(f\"An error occurred during inference of Malicious client: {e}, returning same zero metrics\") \n",
    "                print(f\"An error occurred during inference of Malicious client, returning same zero metrics\")\n",
    "                return float(10000), self.num_examples[\"valset\"], {\"accuracy\": float(0), \"mean_distance\": float(10000), \"validity\": float(0)}\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                loss, accuracy, validity, mean_proximity, hamming_distance, euclidian_distance, iou, variability = self.evaluate_fn(self.model, self.X_val, self.y_val, self.loss_fn, self.X_train, self.y_train, config=self.config_model)\n",
    "                # save loss and accuracy client\n",
    "                utils.save_client_metrics(config[\"current_round\"], loss, accuracy, validity, mean_proximity, hamming_distance, euclidian_distance, iou, variability,\n",
    "                                        self.client_id, self.data_type, config['tot_rounds'], self.history_folder)\n",
    "                return float(loss), self.num_examples[\"valset\"], {\"accuracy\": float(accuracy), \"proximity\": float(mean_proximity), \"validity\": float(validity),\n",
    "                                                                \"hamming_distance\": float(hamming_distance), \"euclidian_distance\": float(euclidian_distance),\n",
    "                                                                \"iou\": float(iou), \"variability\": float(variability)}\n",
    "            except Exception as e:\n",
    "                # print(f\"An error occurred during inference of Malicious client: {e}, returning same zero metrics\") \n",
    "                print(f\"An error occurred during inference of Malicious client, returning same zero metrics\")\n",
    "                return float(10000), self.num_examples[\"valset\"], {\"accuracy\": float(0), \"proximity\": float(10000), \"validity\": float(0),\n",
    "                                                                \"hamming_distance\": float(10000), \"euclidian_distance\": float(10000),\n",
    "                                                                \"iou\": float(0), \"variability\": float(0)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the arguments directly in the notebook\n",
    "class Args:\n",
    "    id = 1  # Example: Set the id to 1 (adjust as needed)\n",
    "    data_type = '2cluster'  # Choose between 'cluster', '2cluster', 'random' (i.e., non-IID and IID)\n",
    "    dataset = 'diabetes'  # Choose between 'diabetes', 'breast', 'synthetic', 'mnist', 'cifar10'\n",
    "    model = 'net'  # Choose between 'net', 'vcnet', 'predictor'\n",
    "    attack_type = 'DP_flip'  # Choose the attack type 'DP_flip', 'DP_inverted_loss', 'MP_noise', 'MP_gradient' \n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the training\n",
    "# model and history folder\n",
    "model = utils.models[args.model]\n",
    "train_fn = utils.trainings[args.model]\n",
    "evaluate_fn = utils.evaluations[args.model]\n",
    "plot_fn = utils.plot_functions[args.model]\n",
    "config = utils.config_tests[args.dataset][args.model]\n",
    "\n",
    "# check if metrics.csv exists otherwise delete it\n",
    "utils.check_and_delete_metrics_file(config['history_folder'] + f\"malicious_client_{args.data_type}_{args.attack_type}_{args.id}\", question=False)\n",
    "\n",
    "# check gpu and set manual seed\n",
    "device = utils.check_gpu(manual_seed=True)\n",
    "\n",
    "# load data\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, num_examples = utils.load_data_malicious(\n",
    "    client_id=str(args.id), device=device, type=args.data_type, dataset=args.dataset, attack_type=args.attack_type)\n",
    "\n",
    "# Model\n",
    "model = model(config=config).to(device)\n",
    "\n",
    "# Optimizer and Loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=config[\"learning_rate\"], momentum=0.9)\n",
    "\n",
    "# Start Flower client\n",
    "client = FlowerClient(model, X_train, y_train, X_val, y_val, optimizer, num_examples, args.id, args.data_type,\n",
    "                        train_fn, evaluate_fn, args.attack_type, config).to_client()\n",
    "fl.client.start_client(server_address=f\"{server_ip_address}:8098\", client=client) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Honest Client**\n",
    "Otherwise from terminal: ```python client.py --id \"2\" --data_type \"2cluster\" --model \"net\" --dataset \"diabetes\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraies and functions\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import utils\n",
    "import flwr as fl\n",
    "import argparse\n",
    "\n",
    "# Define Flower client )\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, X_train, y_train, X_val, y_val, optimizer, num_examples, \n",
    "                 client_id, data_type, train_fn, evaluate_fn, config_model):\n",
    "        self.model = model\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        self.optimizer = optimizer\n",
    "        self.num_examples = num_examples\n",
    "        self.client_id = client_id\n",
    "        self.data_type = data_type\n",
    "        self.train_fn = train_fn\n",
    "        self.evaluate_fn = evaluate_fn\n",
    "        self.history_folder = config_model['history_folder']\n",
    "        self.config = config_model\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        self.model.set_client_id(self.client_id)\n",
    "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        try: \n",
    "            self.set_parameters(parameters)\n",
    "            model_trained, train_loss, val_loss, acc, acc_prime, acc_val, _ = self.train_fn(\n",
    "                self.model, self.loss_fn, self.optimizer, self.X_train, self.y_train, \n",
    "                self.X_val, self.y_val, n_epochs=config[\"local_epochs\"], print_info=False, config=self.config)\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during training of Honest client {self.client_id}: {e}, returning model with error\") \n",
    "        \n",
    "        return self.get_parameters(config), self.num_examples[\"trainset\"], {}\n",
    "    \n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        if self.model.__class__.__name__ == \"Predictor\":\n",
    "            try:\n",
    "                loss, accuracy = utils.evaluate_predictor(self.model, self.X_val, self.y_val, self.loss_fn, config=self.config)\n",
    "                # save loss and accuracy client\n",
    "                utils.save_client_metrics(config[\"current_round\"], loss, accuracy, 0, client_id=self.client_id,\n",
    "                                        data_type=self.data_type, tot_rounds=config['tot_rounds'], history_folder=self.history_folder)\n",
    "                return float(loss), self.num_examples[\"valset\"], {\"accuracy\": float(accuracy), \"mean_distance\": float(0), \"validity\": float(0)}\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred during inference of client {self.client_id}: {e}, returning same zero metrics\") \n",
    "                return float(10000), self.num_examples[\"valset\"], {\"accuracy\": float(0), \"mean_distance\": float(10000), \"validity\": float(0)}\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                loss, accuracy, validity, mean_proximity, hamming_distance, euclidian_distance, iou, variability = self.evaluate_fn(self.model, self.X_val, self.y_val, self.loss_fn, self.X_train, self.y_train, config=self.config)\n",
    "                # save loss and accuracy client\n",
    "                utils.save_client_metrics(config[\"current_round\"], loss, accuracy, validity, mean_proximity, hamming_distance, euclidian_distance, iou, variability,\n",
    "                                        self.client_id, self.data_type, config['tot_rounds'], self.history_folder)\n",
    "                return float(loss), self.num_examples[\"valset\"], {\"accuracy\": float(accuracy), \"proximity\": float(mean_proximity), \"validity\": float(validity),\n",
    "                                                                \"hamming_distance\": float(hamming_distance), \"euclidian_distance\": float(euclidian_distance),\n",
    "                                                                \"iou\": float(iou), \"variability\": float(variability)}\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred during inference of client {self.client_id}: {e}, returning same zero metrics\") \n",
    "                return float(10000), self.num_examples[\"valset\"], {\"accuracy\": float(0), \"proximity\": float(10000), \"validity\": float(0),\n",
    "                                                                \"hamming_distance\": float(10000), \"euclidian_distance\": float(10000),\n",
    "                                                                \"iou\": float(0), \"variability\": float(0)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the arguments directly in the notebook\n",
    "class Args:\n",
    "    id = 1  # Example: Set the id to 1 (adjust as needed, within range 1-100)\n",
    "    data_type = '2cluster'  # Choose between 'cluster', '2cluster', 'random' (i.e., non-IID and IID)\n",
    "    dataset = 'diabetes'  # Choose between 'diabetes', 'breast', 'synthetic', 'mnist', 'cifar10'\n",
    "    model = 'net'  # Choose between 'net', 'vcnet', 'predictor'\n",
    "\n",
    "# Instantiate the Args class\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "# model and history folder\n",
    "model = utils.models[args.model]\n",
    "train_fn = utils.trainings[args.model]\n",
    "evaluate_fn = utils.evaluations[args.model]\n",
    "plot_fn = utils.plot_functions[args.model]\n",
    "config = utils.config_tests[args.dataset][args.model]\n",
    "\n",
    "# check if metrics.csv exists otherwise delete it\n",
    "utils.check_and_delete_metrics_file(config['history_folder'] + f\"client_{args.data_type}_{args.id}\", question=False)\n",
    "\n",
    "# check gpu and set manual seed\n",
    "device = utils.check_gpu(manual_seed=True)\n",
    "\n",
    "# load data\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, num_examples = utils.load_data(\n",
    "    client_id=str(args.id), device=device, type=args.data_type, dataset=args.dataset)\n",
    "\n",
    "# Model\n",
    "model = model(config=config).to(device)\n",
    "\n",
    "# Optimizer and Loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=config[\"learning_rate\"], momentum=0.9)\n",
    "\n",
    "# Start Flower client\n",
    "client = FlowerClient(model, X_train, y_train, X_val, y_val, optimizer, num_examples, args.id, args.data_type,\n",
    "                        train_fn, evaluate_fn, config).to_client()\n",
    "fl.client.start_client(server_address=f\"{server_ip_address}:8098\", client=client) \n",
    "\n",
    "# read saved data and plot\n",
    "plot_fn(args.id, args.data_type, config, show=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CF_FL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
